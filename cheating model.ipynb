{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00b08a-ed62-4739-9a66-1870b78f962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tensorflow.keras import models, layers as tf_layers\n",
    "import mlflow\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def load_audio_file(file_path, sample_rate, duration):\n",
    "    return librosa.load(file_path, sr=sample_rate, duration=duration)\n",
    "\n",
    "def extract_label_from_filename(filename):\n",
    "    return float(filename.split('.')[0])\n",
    "\n",
    "def extract_max_flow_from_filename(filename):\n",
    "    match = re.search(r'Max (\\d+)L', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(\"RETURN max flow of 1 for filename\", filename)\n",
    "        return 1\n",
    "\n",
    "def extract_features(audio, sample_rate, frame_length, feature_type, num_mfcc_features):\n",
    "    samples_per_frame = int(sample_rate * frame_length)\n",
    "    total_frames = int(len(audio) / samples_per_frame)\n",
    "    features = []\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        start_idx = i * samples_per_frame\n",
    "        end_idx = start_idx + samples_per_frame\n",
    "        frame = audio[start_idx:end_idx]\n",
    "\n",
    "        if feature_type == 'mfcc':\n",
    "            feature = librosa.feature.mfcc(y=frame, sr=sample_rate, n_mfcc=num_mfcc_features).T\n",
    "        elif feature_type == 'spectrogram':\n",
    "            feature = np.abs(librosa.stft(frame)).T\n",
    "        elif feature_type == 'raw':\n",
    "            feature = frame\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported feature type\")\n",
    "\n",
    "        features.append(feature if feature_type != 'raw' else feature.reshape(-1, 1))\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def build_model(model_config):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    for layer_config in model_config[\"layers\"]:\n",
    "        layer_type = layer_config.pop(\"type\")\n",
    "        \n",
    "        if layer_type == \"Conv1D\":\n",
    "            model.add(tf_layers.Conv1D(**layer_config))\n",
    "        elif layer_type == \"MaxPooling1D\":\n",
    "            model.add(tf_layers.MaxPooling1D(**layer_config))\n",
    "        elif layer_type == \"Flatten\":\n",
    "            model.add(tf_layers.Flatten())\n",
    "        elif layer_type == \"Dense\":\n",
    "            model.add(tf_layers.Dense(**layer_config))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer type: {layer_type}\")\n",
    "    \n",
    "    model.compile(optimizer=model_config[\"optimizer\"], \n",
    "                loss=model_config[\"loss\"], \n",
    "                metrics=model_config[\"metrics\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_waveform_and_prediction_overlay(file_path, model, sample_rate=44100, frame_length=0.5, feature_type='mfcc', mfcc_num_features=13):\n",
    "    # Load the raw audio file\n",
    "    audio, _ = librosa.load(file_path, sr=sample_rate)\n",
    "    time = np.arange(0, len(audio)) / sample_rate\n",
    "\n",
    "    # Process the audio file for prediction\n",
    "    samples_per_frame = int(sample_rate * frame_length)\n",
    "    total_frames = int(len(audio) / samples_per_frame)\n",
    "    features = []\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        start_idx = i * samples_per_frame\n",
    "        end_idx = start_idx + samples_per_frame\n",
    "        frame = audio[start_idx:end_idx]\n",
    "        # Depending on the feature type, process the frame accordingly\n",
    "        if feature_type == 'mfcc':\n",
    "            feature = librosa.feature.mfcc(y=frame, sr=sample_rate, n_mfcc=mfcc_num_features).T\n",
    "        elif feature_type == 'raw':\n",
    "            feature = frame.reshape(-1, 1)  # Reshape for consistency with (sequence_length, num_features)\n",
    "        features.append(feature)\n",
    "\n",
    "    features = np.array(features)\n",
    "    # If raw audio, pad sequences to the same length\n",
    "    if feature_type == 'raw':\n",
    "        max_length = max(len(f) for f in features)\n",
    "        features = np.array([np.pad(f, ((0, max_length - len(f)), (0, 0)), 'constant') for f in features])\n",
    "        features = np.expand_dims(features, -1)  # Add the num_features dimension\n",
    "\n",
    "    predicted_flow_rates = model.predict(features).flatten()\n",
    "\n",
    "    known_max_flow = extract_max_flow_from_filename(os.path.basename(file_path))\n",
    "    predicted_max_flow = np.max(predicted_flow_rates)\n",
    "    top_predictions = np.percentile(predicted_flow_rates, 90)\n",
    "    adjusted_median = np.median(predicted_flow_rates[predicted_flow_rates >= top_predictions])\n",
    "\n",
    "    # Plot the waveform\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 4))\n",
    "    ax1.plot(time, audio, label='Waveform', color='b')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Amplitude', color='b')\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "    # Create a second y-axis for the predicted flow rate\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(np.linspace(0, time[-1], len(predicted_flow_rates)), predicted_flow_rates, label='Predicted Flow Rate', color='r', alpha=0.7)\n",
    "    ax2.set_ylabel('Flow Rate', color='r')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "    # Title and grid\n",
    "    plt.title(os.path.basename(file_path))\n",
    "    ax1.grid(True)\n",
    "\n",
    "    max_flow_error = abs(known_max_flow - predicted_max_flow)\n",
    "    max_flow_percentage_error = (abs(known_max_flow - predicted_max_flow) / known_max_flow) * 100\n",
    "    median_flow_error = abs(known_max_flow - adjusted_median)\n",
    "    median_flow_percentage_error = (abs(known_max_flow - adjusted_median) / known_max_flow) * 100\n",
    "\n",
    "    overestimation_threshold = 0.1\n",
    "    # Define the threshold for overestimation\n",
    "    threshold = known_max_flow * (1 + overestimation_threshold)\n",
    "    \n",
    "    # Count the number of times predictions exceed this threshold\n",
    "    overestimations = np.sum(predicted_flow_rates > threshold)\n",
    "\n",
    "    return max_flow_error, max_flow_percentage_error, median_flow_error, median_flow_percentage_error, overestimations\n",
    "\n",
    "def load_data(folder, sample_rate=44100, duration=10, feature_type='mfcc', frame_length=0.5, num_mfcc_features=13, load_labels=True):\n",
    "    features, labels = [], []\n",
    "\n",
    "    def process_file(filename):\n",
    "        if not filename.endswith('.wav'):\n",
    "            return None, None\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        audio, _ = librosa.load(file_path, sr=sample_rate, duration=duration)\n",
    "\n",
    "        if load_labels:\n",
    "            label = extract_label_from_filename(filename)\n",
    "        else:\n",
    "            label = None\n",
    "\n",
    "        feature = extract_features(audio, sample_rate, frame_length, feature_type, num_mfcc_features)\n",
    "        return feature, label\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_file, os.listdir(folder)))\n",
    "\n",
    "    for feature, label in results:\n",
    "        if feature is not None:\n",
    "            features.extend(feature)\n",
    "            if load_labels and label is not None:\n",
    "                labels.extend([label] * len(feature))\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels) if load_labels else None\n",
    "\n",
    "    # Log shape of features and labels\n",
    "    logging.info(f\"Features shape: {features.shape}\")\n",
    "    if load_labels:\n",
    "        logging.info(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "    if feature_type == 'raw':\n",
    "        features = pad_sequences(features, maxlen=int(sample_rate * frame_length), padding='post', truncating='post', dtype='float32')\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def run_experiment(config):\n",
    "    with mlflow.start_run():\n",
    "        # Load training, validation, and test data\n",
    "        train_features, train_labels = load_data(\n",
    "            folder=config[\"data\"][\"train_folder\"],\n",
    "            sample_rate=config[\"data\"][\"sample_rate\"],\n",
    "            duration=config[\"data\"][\"duration\"],\n",
    "            feature_type=config[\"data\"][\"feature_type\"],\n",
    "            frame_length=config[\"data\"][\"frame_length\"],\n",
    "            num_mfcc_features=config[\"data\"][\"num_mfcc_features\"],\n",
    "            load_labels=config[\"data\"][\"load_labels\"]\n",
    "        )\n",
    "\n",
    "        val_features, val_labels = load_data(\n",
    "            folder=config[\"data\"][\"val_folder\"],\n",
    "            sample_rate=config[\"data\"][\"sample_rate\"],\n",
    "            duration=config[\"data\"][\"duration\"],\n",
    "            feature_type=config[\"data\"][\"feature_type\"],\n",
    "            frame_length=config[\"data\"][\"frame_length\"],\n",
    "            num_mfcc_features=config[\"data\"][\"num_mfcc_features\"],\n",
    "            load_labels=config[\"data\"][\"load_labels\"]\n",
    "        )\n",
    "\n",
    "        test_features, test_labels = load_data(\n",
    "            folder=config[\"data\"][\"test_folder\"],\n",
    "            sample_rate=config[\"data\"][\"sample_rate\"],\n",
    "            duration=config[\"data\"][\"duration\"],\n",
    "            feature_type=config[\"data\"][\"feature_type\"],\n",
    "            frame_length=config[\"data\"][\"frame_length\"],\n",
    "            num_mfcc_features=config[\"data\"][\"num_mfcc_features\"],\n",
    "            load_labels=config[\"data\"][\"load_labels\"]\n",
    "        )\n",
    "\n",
    "        config[\"model\"][\"input_shape\"] = train_features.shape[1:]\n",
    "        mlflow.log_params(config[\"model\"])\n",
    "        \n",
    "        model = build_model(config[\"model\"])\n",
    "\n",
    "        \n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=3, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_features, \n",
    "            train_labels, \n",
    "            validation_data=(val_features, val_labels), \n",
    "            epochs=config[\"model\"][\"epochs\"],\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        model.summary()\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss, test_mae = model.evaluate(test_features, test_labels)\n",
    "        mlflow.log_metrics({\"test_loss\": test_loss, \"test_mae\": test_mae})\n",
    "\n",
    "        mlflow.log_metrics({\"final_loss\": history.history[\"loss\"][-1], \"final_val_loss\": history.history[\"val_loss\"][-1]})\n",
    "\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history.history['loss'], label='Training loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            plot_path = os.path.join(tempdir, \"training_validation_loss.png\")\n",
    "            plt.savefig(plot_path)\n",
    "            mlflow.log_artifact(plot_path, \"plots\")\n",
    "            plt.close()\n",
    "\n",
    "            # Log test predictions\n",
    "            test_predictions = model.predict(test_features).flatten()\n",
    "            test_results = pd.DataFrame({\n",
    "                \"True Value\": test_labels,\n",
    "                \"Predicted Value\": test_predictions\n",
    "            })\n",
    "\n",
    "            test_results_path = os.path.join(tempdir, \"test_results.csv\")\n",
    "            test_results.to_csv(test_results_path, index=False)\n",
    "            mlflow.log_artifact(test_results_path, \"test_predictions\")\n",
    "\n",
    "# Configuration dictionary\n",
    "config = {\n",
    "    \"data\": {\n",
    "        \"sample_rate\": 44100,\n",
    "        \"duration\": 10,\n",
    "        \"feature_type\": \"raw\",\n",
    "        \"frame_length\": 0.05,\n",
    "        \"train_on_label_0\": True,\n",
    "        \"num_mfcc_features\": 13,\n",
    "        \"load_labels\": True,\n",
    "        \"train_folder\": r\"D:\\file_train\",       # Folder containing training files r\"F:\\test\\Sonohaler\\train\"\n",
    "        \"val_folder\": r\"D:\\file_val\",       # Folder containing validation files\n",
    "        \"test_folder\": r\"D:\\file_test\"          # Folder containing test files r\"F:\\test\\Sonohaler\\test\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"layers\": [\n",
    "            {\"type\": \"Conv1D\", \"filters\": 32, \"kernel_size\": 5, \"activation\": \"relu\"},\n",
    "            {\"type\": \"MaxPooling1D\", \"pool_size\": 2},\n",
    "            {\"type\": \"Conv1D\", \"filters\": 64, \"kernel_size\": 5, \"activation\": \"relu\"},\n",
    "            {\"type\": \"MaxPooling1D\", \"pool_size\": 2},\n",
    "            {\"type\": \"Flatten\"},\n",
    "            {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "            {\"type\": \"Dense\", \"units\": 1, \"activation\": \"linear\"}\n",
    "        ],\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"optimizer_learning_rate\": 0.001,\n",
    "        \"loss\": \"mean_squared_error\",\n",
    "        \"metrics\": [\"mae\"],\n",
    "        \"epochs\": 100,\n",
    "        \"validation_split\": 0.1,  # This will be overridden by validation_data parameter\n",
    "        \"input_shape\": (2205, 1)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Running the experiment\n",
    "run_experiment(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
